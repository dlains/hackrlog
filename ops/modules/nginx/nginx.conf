# This Nginx config was created with help from https://calomel.org/nginx.html

# The user and group the child processes will run as. You may need to make
# this user and group if you install Nginx from source. Make sure this user is
# completely unprivileged or at least runs with the least privileges necessary
# to make the server work.

user                        www-data www-data

# The general rule of the thumb is to set the number of nginx workers to two(2)
# or the number of CPUs your server has; which ever is greater. But, on most
# servers you will find out that two(2) workers serve pages quickly and put less
# load on the server.

worker_processes            2;

# The maximum number file descriptors (ulimit -n) that can be opened by EACH 
# worker_processes.

worker_rlimit_nofile        1024;

events {
  
  # This is the amount of client connections a single child process will handle
  # by themselves at any one time. (default: 1024) Note: Multiply worker_processes
  # times worker_connections for the total amount of connections Nginx will handle.
  # Our example is setup to handle 2*64=128 concurrent connections in total.

  worker_connections        64;
}

http {

  # the definition file nginx loads to identify all of the mime types. These
  # directive simply allow our server to send the the proper file type and
  # application type to the clients.

  include                   mime.types;
  
  # The default type if a file extension has not already be defined in the mime.types
  # file. This is useful if you serve out files with no extension or of a non standard
  # extension. Either way, clients will be able to retrieve the file un-obstructed.
  # Useful for font files declared in CSS with @font-face. There is no defined MIME
  # type yet for the different font formats, so send them as octet-stream. You will
  # see a warning in browser developer tools, but it can be ignored. Keep an eye open
  # for some standard font format MIME types.

  default_type              application/octet-stream;

  #######################################################################################
  # Size Limits: These directive specify the buffer size limitations on the amount of
  # data we will consider to be valid for a request. If the client sends to much data
  # in one request, for example in a buffer overflow attack, then the request will be
  # denied.
  
  # If the request body is more than the buffer, then the entire request body or some
  # part is written in a temporary file.

  #client_body_buffer_size   8k;
  
  # the limit on the size of all of the http headers the client can send to the server.
  # For the overwhelming majority of requests a buffer size of 1K is sufficient. The
  # only time you would need to increase this is if you have a custom header or a large
  # cookie sent from the client.

  client_header_buffer_size  2k;

  # the maximum accepted body size of client request, indicated by the line "Content-Length"
  # in the header of request. If size exceeds this value the client gets sent the error
  # "Request Entity Too Large" (413). If you expect to receive files uploaded to your server
  # through the POST request method you should increase this value.

  client_max_body_size       1m;
  
  # the limit of the URI request line which can not be larger than the buffer size multiplied
  # by the amount of buffers. In our example we accept a buffer size of 1 kilobyte and there
  # is only one(1) buffer. So, will not accept a URI which is larger than (1x1K=1K) 1 kilobyte
  # of data. If the client sends a bigger request then Nginx will return an error "Request URI
  # too large" (414).

  large_client_header_buffers 1 1k/2k;

  
  #######################################################################################
  # Timeouts: These values specify the amount of time in seconds that Nginx will wait
  # for the client to complete the specified action. A keepalive of 300 seconds is a good
  # value as browsers will wait from 120 to 300 seconds to drop the keepalive connection.
  # If you close the connection and browser thinks it is still open the result to the client
  # will look as if the web site is responding slowly; in truth the browse sends request
  # over a closed keepalive connection, has to timeout and then resend the request. Also,
  # 300 seconds is the timeout of most SSL keys. For the other timeout 60 seconds (default
  # of 60 seconds) is normally fine.
  
  # The read timeout for the request body from client. If after this time the client sends
  # nothing, nginx returns error "Request time out" (408). You may want to lower this value
  # to around 5 seconds protect yourself from attacks like Slowloris DoS attack explained lower
  # on this page.

  client_body_timeout        60;
  
  # the timeout reading the title of the request of the client. If after this time the client
  # send nothing, nginx returns error "Request time out" (408). Just like stated before, this
  # value can be lowered to as little as 5 seconds to help mitigate attacks like the Slowloris
  # DoS attack explained lower on this page.

  client_header_timeout      60;
  
  # The first value is for keep-alive connections with the client. The second parameter assigns
  # the value "Keep-Alive: timeout=time" in the header of answer. With the complexity today's
  # websites keep-alive are critical to keeping clients load times to a minimum. Establishing a
  # TCP connection is very expensive in terms of time. It is very efficient for a client to
  # establish its first set of connections (Firefox makes 4 for example) and request all of the
  # objects on the page through those connections. A problem with keepalives to be aware of is
  # every browser, and every version of each browser, has a different timeout the use for keep
  # alives. Firewalls also have their own connection timeouts which may be shorter then the keep
  # alives set on either the client or server. This means browsers, servers and firewalls all have
  # to be in alignment so that keeps alives work. If not, the browser will try to request something
  # over a connection which will never work which results in pausing and slowness for the user.
  # Google Chrome got around this timeout issue by sending a keepalive every 45 seconds until the
  # browser's default 300 second timeout limit. You can do your part by setting firewall timeouts
  # no less then 600 seconds and allowing clients to keep a connection open to your server for at
  # least 300 seconds.

  keepalive_timeout          300 300;

  # Response timeout to the client. Timeout is established not on the entire transfer of answer,
  # but only between two operations of reading, if after this time client will accepts nothing,
  # then nginx is shutting down the connection. You may want to look at lowering this value
  # (5 seconds is ok) if you have malicious clients opening connection and not closing them like
  # in the Slowloris DoS attack explained lower on this page.
  
  send_timeout               60;

  #######################################################################################
  # General Options
  
  # The number of requests which can be made over a keep-alive connection. If a client makes 4
  # connections to your server (Firefox's default is 4 initial connections for example) they have
  # 4 keepalive channels. If you set keepalive_requests to 20 like in our example above that would
  # give a client 80 objects to request through those 4 connections. Keep alive requests are a lot
  # faster and more efficient then having the client make 80 individual TCP connections. Try to set
  # your keepalive_requests high enough so that a browser can request at least double what an
  # average user requests in 300 seconds (keepalive_timeout 300 300;). So, lets say I have a web
  # site and the average amount of objects (pictures, css. html, js, ect. ) is 20 per page. Lets
  # also say that the average browser looks at 2 pages in 300 seconds (5 minutes). You may want to
  # keep keepalive_requests set at 20 as this would serve 2 pages times 20 objects which equals 40
  # requests in 300 seconds easily. Remember keepalive_requests at 20 times 4 connections was 80
  # requests total. Why not just set keepalive_requests really high ? You always want to put a limit on
  # clients in case a malicious user attacks your site.

  keepalive_requests         20;

  # Enables the use of sendfile(). Sendfile relies on the OS to do actual IO, and this may be a good idea
  # if you are serving large files, if your OS is a little slow like OpenBSD or if you are letting the OS
  # cache the data. You need to be careful about using sendfile if the file being sent has any possibility
  # of being modified ( especially truncated ) while the operation is in progress since some very odd
  # things ( like the process crashing ) can happen on some platforms. You may just want to test your server
  # with sendfile on and off. We like to keep sendmail on as our site is serving small static files.
  
  sendfile                   off;

  charset                    utf-8;
  source_charset             utf-8;
  
  # Throws away non-standard headers in the client request. If you do not expect to receive any
  # custom made headers then make sure to enable this option.
  
  ignore_invalid_headers     on;
  
  # Allows the use of the error_pages directive specified later in the config.
  
  recursive_error_pages      on;
  
  # Off disables nginx's version numbers in the auto generated error pages. We do not want to display
  # this information for security purposes.
  
  server_tokens              off;
  
  # Off disables the server's ability to substitute the client supplied "Host" header with the virtual
  # server variable "server_name" when a client is redirected.
  
  server_name_in_redirect    off;
  
  #######################################################################################
  # TCP Options: These options determine how nginx should use the TCP stack.
  
  # If set, don't send out partial frames. All queued partial frames are sent when the
  # option is cleared again. This is useful for pre-pending headers before calling
  # sendfile(2), or for throughput optimization. As currently implemented, there is a 200
  # millisecond ceiling on the time for which output is corked by TCP_CORK. If this ceiling
  # is reached, then queued data is automatically transmitted. tcp_nopush is off by default
  # and we did not see a reason to change that.
  
  tcp_nopush                 off;
  
  # TCP_NODELAY is for a specific purpose; to disable the Nagle buffering algorithm. It
  # should only be set for applications that send frequent small bursts of information
  # without getting an immediate response, where timely delivery of data is required (the
  # canonical example is mouse movements). BY default tcp_nodelay is on and this is a good
  # setting.

  tcp_nodelay                on;
  
  #######################################################################################
  # Compression Options: These values tell nginx how to compress outgoing data. Remember that
  # all files of the specified mime.type (gzip_types) are compressed in real time. On a
  # P3 500MHz a 100KB HTML file takes 0.05 seconds (5 hundredths of a second) to gzip at
  # level 9 compression (highest).
  
  # turn real time compression on. You may want to disable this option if you decide to use the
  # more efficient gzip_static instead. You always want to gzip compress your HTML pages as most
  # clients have plenty of extra CPU cycles, but limited internet bandwidth. Also, using this
  # option to compress data in real time adds a response delay back to the client. If you are
  # compressing the same HTML code to every client then this is just wasting time. Disable this real
  # time gzip and use gzip_static instead. Then you can pre-compress your html files and increase
  # your response times.
  
  gzip                       on;

  # Allows one to have pre-compressed .gz files served instead of compressing files on the fly.
  # This is the most efficient method of serving compressed data. To use this option simply have
  # a compressed copy of the same .html file in document root. For example, if we have the index.html
  # file in place we will also have a pre-compressed index.html.gz file. You will have a
  # non-compressed copy for older client that do not accept compression and a pre-compressed copy for
  # all other clients. gzip_static does not depend on the gzip filter nginx module. You can use
  # gzip_static without compiling the gzip filter.
  
  #gzip_static               off;
  
  # Allows 16 slots of 8k buffers used to respond to clients with a gzip'd response. This means the
  # max size of our compressed responses can be no larger than 16*8=128 kilobytes. By default Nginx
  # limits compressed responses to 4*8k= 32 kilobytes. If you expect to return responses which
  # compressed size is more than 32KB in size then increase the number of buffers (e.g. 16). The single
  # buffer size of 8K can not be increased.
  
  #gzip_buffers              16 8k;
  
  # 1.0 allows the server to send compressed data to HTTP/1.0 clients. HTTP/1.1 clients use the
  # proper headers so they can always ask for compressed data.
  
  gzip_http_version          1.0;
  
  # set at 1 compresses files to the lowest compression level. Level 1 is the fastest/lowest
  # compression and level 9 is the slowest/best compression. During testing the time difference
  # between level 1 and 9 was around 2 hundredths of a second per file on a P3 500MHz. Two(2)
  # hundredths of a second is about the same amount of time the entire page should be rendered.
  
  gzip_comp_level            5;

  # set to 0 means that nginx should compress all files no matter what the size. The value is the
  # size in bytes. You can always set this value to something higher if you do not wish to compress
  # small files.
  
  gzip_min_length            100;

  # are the only files types to be compressed. For example, JPG's are already compressed so it
  # would be useless for us to try to compress them again. TXT and BMP files on the other hand
  # compress very well at an average of 250% smaller. Smaller files mean less bandwidth used and
  # less time to transmit the same amount of data. This makes your site "feel" significantly faster.
  
  gzip_types                 text/plain text/html text/css text/xml image/x-icon image/gif;
  
  # Enables the response header "Vary: Accept-Encoding". This way clients know that our server has
  # the ability to send out compressed data.
  
  gzip_vary                  on;
  
  #######################################################################################
  # Log Format
  
  # The log format of the web logs. This format is assigned to the variable "main" and can be used
  # later in the http section. This format is fully compatible with standard log analyzing tools
  # like Awstats, Webalizer and custom tools like the Calomel.org Web Log Sentry. We also have added
  # two(2) more fields at the end of each log line. "$request_time" logs how much time the server took
  # to generate the content and "$gzip_ratio" shows what X-factor the file was compressed by. A value
  # of 2.50 means the file was compressed 250%.
  
  log_format main '$remote_addr $host $remote_user [$time_local] "$request" $status $body_bytes_sent "$http_referer" "$http_user_agent"';
  
  # The following directives include site specific configuration.
  include /etc/nginx/conf.d/hackrlog.conf;
}